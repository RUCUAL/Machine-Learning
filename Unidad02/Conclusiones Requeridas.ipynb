{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvx67Z/lLZO6FtvsB9Nj8T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RUCUAL/Machine-Learning/blob/main/Unidad02/Conclusiones%20Requeridas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Interpretación vs. Predicción: Coeficientes de la RLM**\n",
        "\n",
        "La Regresión Lineal Múltiple (RLM) es el modelo ideal para la interpretación, ya que sus coeficientes indican la magnitud y dirección del impacto de cada variable sobre la tasa de asesinatos, manteniendo todas las demás variables constantes (ceteris paribus).\n",
        "\n",
        "#**2. Mejor Rendimiento: Algoritmo con el R2 más Alto**\n",
        "\n",
        "El algoritmo que arrojó el valor de R2 más alto en el conjunto de prueba es el [XGBoost o Random Forest] con un Rprueba2​ de [Valor R2, Ej: 0.9150].\n",
        "\n",
        "¿A qué se debe su superioridad?\n",
        "\n",
        "La superioridad se debe a su naturaleza de aprendizaje de ensamblaje (Ensemble Learning) basado en árboles:\n",
        "\n",
        "**XGBoost:** Utiliza la técnica de Boosting (Gradient Boosting), que entrena árboles secuencialmente. Cada nuevo árbol intenta corregir los errores (residuos) del árbol anterior. Este enfoque tiende a minimizar el sesgo (bias) de manera muy efectiva, resultando en un rendimiento predictivo superior.\n",
        "\n",
        "**Random Forest:** Utiliza la técnica de Bagging (Bootstrap Aggregating), donde entrena múltiples árboles de forma independiente y promedia sus predicciones. Esto es extremadamente efectivo para reducir la varianza, lo que lo hace muy robusto contra el ruido y el sobreajuste.\n",
        "\n",
        "Los modelos de ensamblaje (XGBoost y RF) son capaces de capturar relaciones no lineales complejas e interacciones entre variables que los modelos lineales (RLM) simplemente no pueden detectar.\n",
        "\n",
        "#**3. Importancia de Variables: Comparación RLM vs. No Lineales**\n",
        "\n",
        "**RLM: **Solo mide la fuerza de la relación lineal individual de cada variable con el objetivo. Si dos variables están altamente correlacionadas, la RLM puede \"elegir\" una y asignarle un coeficiente grande, mientras que la otra queda con un coeficiente pequeño (efecto de multicolinealidad).\n",
        "\n",
        "**XGBoost/RF:** Miden la contribución total a la reducción de impureza (o error) a lo largo de todos los nodos y todos los árboles. Estas métricas capturan interacciones complejas y la importancia no lineal de la variable. Es común que las variables que funcionan bien en conjunto (interacciones) sean mejor valoradas por los modelos basados en árboles que por la RLM.\n",
        "\n",
        "#**4. Sobreajuste (Overfitting): Árbol de Decisión**\n",
        "\n",
        "El sobreajuste ocurre cuando el modelo memoriza el conjunto de entrenamiento (incluyendo el ruido) en lugar de aprender los patrones subyacentes.\n",
        "\n",
        "La evidencia es la gran diferencia entre las métricas de rendimiento:\n",
        "\n",
        "    R2 de Entrenamiento: [Valor, Ej: 1.0000]\n",
        "\n",
        "    R2 de Prueba: [Valor, Ej: 0.6500]\n",
        "\n",
        "    Diferencia: [Diferencia, Ej: 0.3500]\n",
        "\n",
        "Un R2 de entrenamiento de 1.00 significa que el modelo explicó perfectamente el 100% de la varianza en los datos que ya había visto. Sin embargo, un R2 de prueba mucho más bajo (por ejemplo, 0.6500) indica que esta \"perfecta\" capacidad predictiva no se trasladó a los nuevos datos, probando que el modelo falló en la generalización.\n",
        "\n",
        "#**5. Recomendación de Modelo: Argumentos de Inversión Pública**\n",
        "\n",
        "Si el objetivo es convencer al gobierno de invertir en un programa social específico, el modelo recomendado es la Regresión Lineal Múltiple (RLM) o, en su defecto, un Árbol de Decisión de Profundidad Limitada (max_depth=3 o 4).\n",
        "\n",
        "Justificación:\n",
        "\n",
        "La decisión de inversión pública requiere transparencia y causalidad (o al menos fuerte correlación interpretable), no solo la mejor predicción.\n",
        "\n",
        "**Interpretación (RLM):** La RLM es la más adecuada. Permite decir: \"Por cada aumento de 1 unidad en [Variable de inversión, Ej: inversión_programas_sociales_per_capita], la tasa de asesinatos disminuye en [Valor del coeficiente] unidades, manteniendo todos los demás factores constantes\". Esta declaración clara y cuantificable es esencial para justificar el gasto público.\n",
        "\n",
        "\n",
        "**Modelos de Ensamble (RF/XGBoost):** Aunque ofrecen el R2 más alto, son cajas negras (Black Boxes). Un gobierno no puede justificar una inversión de millones de pesos diciendo: \"Lo predijimos con XGBoost porque es el mejor R2\". Necesitan saber por qué la inversión funciona. Por lo tanto, la interpretabilidad supera la precisión pura en este escenario."
      ],
      "metadata": {
        "id": "2JR_rSToLzH6"
      }
    }
  ]
}